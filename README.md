# Alignment Research Engine Accelerator (ARENA) 3.0 Course with a focus on Mechanistic Interpretability

## Overview

This repository contains my work and notes for **Chapters 0 and 1** of the ARENA (Alignment Research Engineer Accelerator) course. I am going to focus on developing skills in **mechanistic interpretability**, with an emphasis on transformer models and Sparse AutoEncoders. 

## Objectives

1. **Chapter 0: Fundamentals**
   - Revisit essential Deep Learning concepts: linear algebra, backpropagation, optimization, PyTorch fundamentals.
   - Master advanced tensor manipulation with **Einops** and **Einsum**. 

2. **Chapter 1: Transformers & Mechanistic Interpretability**
   - Understand the architecture of transformers, including attention mechanisms and embeddings.
   - Explore the internal mechanisms of transformers using tools like `TransformerLens`.
   - Conduct experiments to reverse-engineer model behaviors and interpret attention heads and circuits.

## Repository Structure

```
ARENA3.0-course/
├── Chapter0/
|   ├── README.md             # Summary of key topics of Chapter 0.
│   ├── exercises/            # Completed exercises and code snippets.
├── Chapter1/
│   ├── README.md             # Summary of key topics of Chapter 1.
│   ├── experiments/          # Code and results for interpretability experiments.
│   ├── projects/             # Mini-projects exploring transformers and circuits.
├── README.md                 # Overview of the repository (this file).
└── LICENSE                   # License for the repository (if applicable).
```

## Tools and Libraries
- **Python 3.9+**
- **Jupyter Notebook**
- **TransformerLens**
- **PyTorch**
- **Matplotlib** (for visualizations)

## Acknowledgments
This work is part of the ARENA course:
- [Callum McDougall ARENA content source](https://github.com/callummcdougall/ARENA_3.0/tree/main)
- [ARENA website](https://www.arena.education))
